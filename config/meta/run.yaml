# @package _global_
# training (debug)

# tensorboard --host localhost --port 8080 --logdir=./outputs

run_type: "debug" # "test"
debug_lvl: 1 #2  # 0 disables debugging and verbosity completely, >1 activates additional debugging functionality
global_seed: 1234

# global logging
log_lvl: INFO   # ERROR
tb_log_path: 'logs/tb/'
val_log_path: 'logs/val/'

#
model_args:
  seed: $(global_seed)
  num_workers: 4
  pin_memory: True

  train_dataset_size: #None (=all)
  train_batch_size: 128

  val_dataset_size: #None (=all)
  val_batch_size: 64

  # optimizer args
  # ==============================================
  optimizer: Adam
  optimizer_cfg:
    lr: 0.001
    weight_decay: 0
  scheduler_cfg:
    schedule_type: "step"
    decay: 0.55
    decay_step: 40

#
trainer_args:
  resume_from_checkpoint: #None
  accelerator: 'gpu'
  devices: 1
  max_epochs: 200
  check_val_every_n_epoch: 1

  # misc
  precision: 32
  gradient_clip_val: 0.5    # grad clip l2 norm value
  gradient_clip_algorithm: 'norm'
  deterministic: False      # enables cudnn.deterministic
  benchmark: True          # speed up in case input size is constant (cudnn.benchmark)
  #accumulate_grad_batches: 1
  # https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html
  # EARLY stopping: https://pytorch-lightning.readthedocs.io/en/stable/common/early_stopping.html

  # train/val logging
  log_every_n_steps: 20
  enable_progress_bar: True

  # profiling / debugging args
  fast_dev_run: False #True          # fast debug run
  device_stats: False #True
  profiler: #"advanced"
  overfit_batches: 0.0        # try repeatedly fitting on % of data, if it does not converge, there is a bug!
  enable_model_summary: False #True
  track_grad_norm: -1 #2     # corresponding p-norm, -1 to disable

# checkpointing
checkpoint_path: 'checkpoints/'
checkpoint_args:
  save_last: True   # save last ckpt independent of val_cost
  save_top_k: 2   # num checkpoints to keep, if None saves only last
  monitor: "val_acc"    # quantity to monitor
  mode: "max"
  filename: "{epoch}_{val_acc:.4f}"
