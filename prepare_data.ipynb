{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Code to prepare labeled CCP training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.11.0 \n",
      "pytorch CUDA version: 11.3 \n",
      "pytorch CUDA available: True \n",
      "--------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from lib.problems.generator import ProblemDataset, Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SIZE = 4096     # size of dataset\n",
    "K = (3, 12)\n",
    "N = 200             # number of nodes\n",
    "SEED = 1234\n",
    "MAX_CAP = 1.1   # [1.05, 1.1, 1.2, 1.5]\n",
    "COORDS_DIST = \"gm\"      # [gm, mixed]\n",
    "UNF_FRAC = 0.2  # fraction of uniformly sampled coords for mixed data\n",
    "\n",
    "k = K\n",
    "if isinstance(K, tuple):\n",
    "    k = f\"{K[0]}-{K[1]}\"\n",
    "    K = (K[0], K[1]+1)  # second value is exclusive in generator!\n",
    "dist = COORDS_DIST if COORDS_DIST == \"gm\" else f\"{COORDS_DIST}_unf{UNF_FRAC}\"\n",
    "\n",
    "save_pth = f\"./data/CCP/CCP{N}/\"\n",
    "data_pth = save_pth + f\"raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part6.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part7.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part3.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part4.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part5.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part2.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part4.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part0.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part7.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part6.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part3.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part0.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part2.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part5.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part1.npz', 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_part1.npz']\n"
     ]
    },
    {
     "data": {
      "text/plain": "['train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part6.npz',\n 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part7.npz',\n 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part3.npz',\n 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part2.npz',\n 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part4.npz',\n 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part0.npz',\n 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part5.npz',\n 'train_gm_n200_k3-12_s4096_cap1_1_seed1234_labeled_part1.npz']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(data_pth)\n",
    "print(files)\n",
    "lbl_files = [f for f in files if \"label\" in f]\n",
    "lbl_files.sort()\n",
    "lbl_files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge parts\n",
    "dataset = [Generator.load_dataset(os.path.join(data_pth, f)) for f in lbl_files]\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "4052"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = list(it.chain.from_iterable(dataset))\n",
    "len(ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "Dataset file with same name exists already. Overwrite file? (y/n)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'data/CCP/CCP200/train_gm_n200_k3-12_s4000_cap1_1_seed1234.npz'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = ds[:4000]\n",
    "size = len(train_ds)\n",
    "print(size)\n",
    "fname = f\"train_{dist}_n{N}_k{k}_s{size}_cap{str(MAX_CAP).replace('.', '_')}_seed{SEED}.npz\"\n",
    "Generator.save_dataset(train_ds, filepath=os.path.join(save_pth, fname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "Dataset file with same name exists already. Overwrite file? (y/n)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'data/CCP/CCP200/val_gm_n200_k3-12_s52_cap1_1_seed1234.npz'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = ds[4000:]\n",
    "size = len(val_ds)\n",
    "print(size)\n",
    "fname = f\"val_{dist}_n{N}_k{k}_s{size}_cap{str(MAX_CAP).replace('.', '_')}_seed{SEED}.npz\"\n",
    "Generator.save_dataset(val_ds, filepath=os.path.join(save_pth, fname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merging parts for shanghai and italia telecom datasets and the VRP data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Telecom datasets\n",
    "PROBLEM = \"ccp\"\n",
    "DSET = \"telecom_italia\" #\"shanghai_telecom\"\n",
    "P_SIZE = 512     # size of part\n",
    "N_PARTS = 10\n",
    "SIZE = N_PARTS*P_SIZE\n",
    "\n",
    "SEED = 1234\n",
    "N = 200\n",
    "CAP = 1.1\n",
    "\n",
    "save_pth = f\"./data/CCP/benchmark/{DSET}/sub/\"\n",
    "data_pth = save_pth + f\"raw/\"\n",
    "fname = f\"n{N}_cap{str(CAP).replace('.', '_')}_seed{SEED}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# VRP dataset\n",
    "PROBLEM = \"cvrp\"\n",
    "P_SIZE = 512     # size of part\n",
    "N_PARTS = 10\n",
    "SIZE = N_PARTS*P_SIZE\n",
    "\n",
    "SEED = 1234\n",
    "N = 200\n",
    "CAP = 1.1\n",
    "K = 30\n",
    "coord_samp = 'mixed'  # ['uniform', 'gm', 'mixed']\n",
    "unf_frac = 0.2\n",
    "weight_samp = 'random_k_variant'  # ['random_int', 'uniform', 'gamma', 'random_k_variant']\n",
    "dist = coord_samp if coord_samp == \"gm\" else f\"{coord_samp}_unf{unf_frac}\"\n",
    "\n",
    "save_pth = f\"./data/VRP/VRP{N}/\"\n",
    "data_pth = save_pth + f\"raw/\"\n",
    "fname = f\"{dist}_n{N}_kmax{K}_cap{str(CAP).replace('.', '_')}_seed{SEED}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_n200_s5120_cap1_1_seed1234_part2.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part7.npz', 'train_n200_s5120_cap1_1_seed1234_part4.npz', 'train_n200_s5120_cap1_1_seed1234_part6.npz', 'train_n200_s5120_cap1_1_seed1234_part1.npz', 'train_n200_s5120_cap1_1_seed1234_part8.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part0.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part4.npz', 'train_n200_s5120_cap1_1_seed1234_part7.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part2.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part6.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part3.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part8.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part1.npz', 'train_n200_s5120_cap1_1_seed1234_part5.npz', 'train_n200_s5120_cap1_1_seed1234_part9.npz', 'train_n200_s5120_cap1_1_seed1234_part3.npz', 'train_n200_s5120_cap1_1_seed1234_part0.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part9.npz', 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part5.npz']\n"
     ]
    },
    {
     "data": {
      "text/plain": "['train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part0.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part1.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part2.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part3.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part4.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part5.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part6.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part7.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part8.npz',\n 'train_n200_s5120_cap1_1_seed1234_ccp_mh_labeled_part9.npz']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(data_pth)\n",
    "print(files)\n",
    "lbl_files = [f for f in files if \"label\" in f]\n",
    "lbl_files.sort()\n",
    "lbl_files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded part 0\n",
      "loaded part 1\n",
      "loaded part 2\n",
      "loaded part 3\n",
      "loaded part 4\n",
      "loaded part 5\n",
      "loaded part 6\n",
      "loaded part 7\n",
      "loaded part 8\n",
      "loaded part 9\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i, f in enumerate(lbl_files):\n",
    "    d = Generator.load_dataset(os.path.join(data_pth, f), convert=False)\n",
    "    print(f\"loaded part {i}\")\n",
    "    dataset.append(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "merged_data = {}\n",
    "for d in dataset:\n",
    "    for k, v in d.items():\n",
    "        if k not in ['size', 'problem']:\n",
    "            if k not in list(merged_data.keys()):\n",
    "                merged_data[k] = v\n",
    "            else:\n",
    "                merged_data[k] = np.concatenate((merged_data[k], v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "4981"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_size = len(merged_data['graph_size'])\n",
    "full_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": "'data/CCP/benchmark/telecom_italia/sub/train_s4981_n200_cap1_1_seed1234.npz'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT_IDX = 4900 #5000\n",
    "train_ds = {k: v[:SPLIT_IDX] for k, v in merged_data.items()}\n",
    "size = len(train_ds['graph_size'])\n",
    "print(size)\n",
    "train_ds['problem'] = np.array(\"ccp\")\n",
    "train_ds['size'] = np.array(len(train_ds['graph_size']))\n",
    "sfname = f\"train_s{full_size}_{fname}\"\n",
    "Generator.save_dataset(train_ds, filepath=os.path.join(save_pth, sfname), problem=PROBLEM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "data": {
      "text/plain": "'data/CCP/benchmark/telecom_italia/sub/val_s4981_n200_cap1_1_seed1234.npz'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = {k: v[SPLIT_IDX:] for k, v in merged_data.items()}\n",
    "size = len(val_ds['graph_size'])\n",
    "print(size)\n",
    "val_ds['problem'] = np.array(\"ccp\")\n",
    "val_ds['size'] = np.array(len(val_ds['graph_size']))\n",
    "sfname = f\"val_s{full_size}_{fname}\"\n",
    "Generator.save_dataset(val_ds, filepath=os.path.join(save_pth, sfname), problem=PROBLEM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
